{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    " \n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add precleaned old csv data file \n",
    "data  = pd.read_csv('/Users/urmi/Documents/NLP/Assignment_1/pmc-data-all-new.csv', encoding = \"ISO-8859-1\",converters={'Stemmed_abstract': eval})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.reset_index(drop=True, inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 0'], axis = 1) \n",
    "#data = data.drop(['Unnamed: 0.1'], axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data['Stop word Tokenized abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one = data[data['Article_Id']==3446065]\n",
    "#print(one)\n",
    "#data.iloc[1785355].Article_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#type(data['Stemmed abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add topic csv with 30 entries\n",
    "data_t  = pd.read_csv('/Users/urmi/Documents/NLP/Assignment_1/topic_data_new.csv', encoding = \"ISO-8859-1\",converters={'Stop_word_stemmed_description': eval})\n",
    "#usecols=['Stop word Tokenized description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daat_t = list(data_t['Stop_word_stemmed_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daat_t[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedDocumentIterator(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "        #print(doc_list)\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield TaggedDocument(words=doc, tags=[self.labels_list[idx]])\n",
    " \n",
    "\n",
    "docLabels = list(data['Article_Id'])\n",
    "data_stem = list(data['Stemmed_abstract'])\n",
    "sentences = TaggedDocumentIterator(data_stem, docLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(size=100, window=10, min_count=5, workers=11,alpha=0.025, iter=20)\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences,total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "#model.save('model_similarity_1.doc2vec')\n",
    "# Load the model\n",
    "model_doc = Doc2Vec.load('model_similarity_1.doc2vec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def get_similar(model_id,topic,n):\n",
    "#one = ['58-year-old', 'african-american', 'woman', 'present', 'ER', 'episod', 'pressing/burn', 'anterior', 'chest', 'pain', 'began', 'two', 'day', 'earlier', 'first', 'time', 'life', 'pain', 'start', 'walk', 'radiat', 'back', 'accompani', 'nausea', 'diaphoresi', 'mild', 'dyspnea', 'increas', 'inspir', 'latest', 'episod', 'pain', 'end', 'half', 'hour', 'prior', 'arriv', 'known', 'hypertens', 'obes', 'deni', 'smoke', 'diabet', 'hypercholesterolemia', 'famili', 'histori', 'heart', 'diseas', 'current', 'take', 'medic', 'physic', 'examin', 'normal', 'ekg', 'show', 'nonspecif', 'chang']\n",
    "    new_doc_vec = model_id.infer_vector(daat_t[topic], steps=50, alpha=0.25)\n",
    "    similars = model_id.docvecs.most_similar([new_doc_vec], topn = n)\n",
    "    #print(similars)\n",
    "\n",
    "    sorted_tuples = sorted(similars, key=itemgetter(1),reverse = True)\n",
    "    #print(sorted_tuples)\n",
    "    return sorted_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get_similar(model_doc,0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " #save result in txt file\n",
    "    with open('doc2vec_result.txt','w') as file:\n",
    "        file.write('TOPIC_NO Q0 PMCID RANK SCORE RUN_NAME\\n')\n",
    "        for idxx,question in enumerate(daat_t):\n",
    "            similar_all = get_similar(model_doc,idxx,1000)\n",
    "            #print(idx,similar_all)\n",
    "            for index, tuple in enumerate(similar_all):\n",
    "                a_id = tuple[0]\n",
    "                a_score = tuple[1]\n",
    "               # print(index,tuple)\n",
    "                file.write(f'{idxx+1}\\t{0}\\t{a_id}\\t{index}\\t{a_score}\\t{\"DocVec\"}\\n')\n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(similar_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
